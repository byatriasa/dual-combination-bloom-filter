{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byatrsa/bloomfilter/blob/master/DCOMB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqQ2pFByQrmm"
      },
      "source": [
        "Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXprNrQhSQv0",
        "outputId": "719688d1-9a1b-4553-b65c-8a87ee913854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bitarray\n",
            "  Downloading bitarray-2.3.5.tar.gz (88 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 21.9 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 30 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 40 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 51 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 61 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 71 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 81 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 88 kB 5.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: bitarray\n",
            "  Building wheel for bitarray (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bitarray: filename=bitarray-2.3.5-cp37-cp37m-linux_x86_64.whl size=171997 sha256=ae035ea891334fdfb3e75894765af1388a49c58c0ba3671c85c5263a41898986\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/3f/c2/51401246e3e827137d0ea8fac1ce14508400f4a8f5e50d919a\n",
            "Successfully built bitarray\n",
            "Installing collected packages: bitarray\n",
            "Successfully installed bitarray-2.3.5\n"
          ]
        }
      ],
      "source": [
        "!pip install bitarray\n",
        "\n",
        "import math\n",
        "import time\n",
        "import hashlib\n",
        "import pandas as pd\n",
        "\n",
        "from bitarray import bitarray\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx2djbRxRNMM"
      },
      "source": [
        "# CONFIG: Set constants' value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gdk8rdRaRMu3"
      },
      "outputs": [],
      "source": [
        " # static bloom filter capacity\n",
        "n = 20\n",
        "\n",
        " # default false positive probablity\n",
        "p = 0.001\n",
        "\n",
        " # pk code group size in ubf\n",
        "a = 1000\n",
        "\n",
        "# set the number of block that will be used\n",
        "block_count = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIixmPvoT1AM"
      },
      "source": [
        "# DATASET: Load from CSV\n",
        "Load dataset from prepared csv files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-OtgtFkUYVS"
      },
      "outputs": [],
      "source": [
        "## Read csv dataset\n",
        "source_block_df = pd.read_csv('https://gist.github.com/alanmsmxyz/24cfbeb098ed165892505aafeaea548b/raw/b6054da3ab0fc03c4c0e4a471543ff94494d45e1/bf_block.csv')\n",
        "source_index_df = pd.read_csv('https://gist.github.com/alanmsmxyz/24cfbeb098ed165892505aafeaea548b/raw/b6054da3ab0fc03c4c0e4a471543ff94494d45e1/bf_index.csv')\n",
        "keys_df = pd.read_csv('https://gist.github.com/alanmsmxyz/24cfbeb098ed165892505aafeaea548b/raw/b6054da3ab0fc03c4c0e4a471543ff94494d45e1/bf_keys.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr2Dg1RZQg2K",
        "outputId": "5c97a855-de5f-45b6-98b6-a649f06ebd9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       block_id                                              index\n",
            "0             0  57ce88c29d3090cc656de5fcc4a901b7f3e1ac8ff94e9f...\n",
            "1             0  51c6fd564056fcfbc694f4790b6cac2893736989512ee0...\n",
            "2             0  3fe7b323ed8cd89fa6c2e8a21b89b49309c5699f015686...\n",
            "3             0  e6d04db9125c80d94525f2cbde09a5b3afdaed9cd94e02...\n",
            "4             0  44989af264f3528fc7012772c79b59cbbc223d7951326e...\n",
            "...         ...                                                ...\n",
            "27631       999  51c6fd564056fcfbc694f4790b6cac289373698935bc88...\n",
            "27632       999  3fe7b323ed8cd89fa6c2e8a21b89b49309c5699f4facc1...\n",
            "27633       999  e6d04db9125c80d94525f2cbde09a5b3afdaed9cdf9021...\n",
            "27634       999  44989af264f3528fc7012772c79b59cbbc223d7937b8fc...\n",
            "27635       999  e3c7f9f7913aef3942ae3b839c347ff04e3d7fd3470bd6...\n",
            "\n",
            "[27636 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# filter n amount of block to be used\n",
        "block_df = source_block_df.head(block_count)\n",
        "\n",
        "# get all index for filtered blocks\n",
        "latest_block = block_df['block_id'][len(block_df) - 1]\n",
        "index_df = source_index_df.loc[source_index_df['block_id'] <= latest_block]\n",
        "\n",
        "print(index_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_j-tRkAVAh3"
      },
      "source": [
        "# CLASS: Bloom Filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQL_KkcZSy5U"
      },
      "source": [
        "Class: __Bloom Filter__\n",
        "> Consist of:\n",
        "- Function: __init__: to initialize the class, functions, and class methods functions used\n",
        "- Function: __add__: to insert a specified desired element to the array\n",
        "- Function: __check__: to an existence of a specified element in the array\n",
        "- Function: (classmethod) __get_size__: to calculate the size of the array\n",
        "- Function: (classmethod) __get_hash_count__: to calculate the hash count needed to hash a specified element"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEC-wDJTS1H6"
      },
      "outputs": [],
      "source": [
        "class BloomFilter(object):\n",
        "\n",
        "\t'''\n",
        "\tClass for Bloom filter, using SHA256 hash function\n",
        "\t'''\n",
        "\n",
        "\tdef __init__(self, items_count, fp_prob):\n",
        "\t\t'''\n",
        "    Bloom Filter is a bit of array of specified size (m) and initially sets to zero\n",
        "\n",
        "    Glosarium:\n",
        "\t\t  n = items_count : int\n",
        "\t\t\t  Number of items expected to be stored in bloom filter\n",
        "\t\t  p = fp_prob : float\n",
        "\t\t\t  False Positive probability in decimal\n",
        "      k = hash count\n",
        "        Hash count needed for specified value. Formula commented alongside the function.\n",
        "      m = size of array\n",
        "        m CAN'T BE INPUTED MANUALLY without calculating the items count and hash count. Otherwise, collision increases.\n",
        "\t\t'''\n",
        "\n",
        "\t\t# Initialize false positive probability in decimal\n",
        "\t\tself.fp_prob = fp_prob\n",
        "\n",
        "\t\t# Initialize size (m) of bit array to use\n",
        "\t\tself.size = self.get_size(items_count, fp_prob)\n",
        "\n",
        "\t\t# Initialize number of hash functions (k) to use\n",
        "\t\tself.hash_count = self.get_hash_count(self.size, items_count)\n",
        "\n",
        "\t\t# Initialize bit array of given size\n",
        "    # Creating the array that will use the bloom filter method\n",
        "\t\tself.bit_array = bitarray(self.size)\n",
        "\n",
        "\t\t# Initialize all bits as 0\n",
        "\t\tself.bit_array.setall(0)\n",
        "\n",
        "\t@classmethod\n",
        "\tdef from_bit_array(self, text, n, fp_prob):\n",
        "\t\tba = bitarray(len(text))\n",
        "\n",
        "\t\tfor i in range(len(text)):\n",
        "\t\t\tba[i] = int(text[i])\n",
        "\n",
        "\t\tbf = BloomFilter(n, fp_prob)\n",
        "\n",
        "\t\tbf.bit_array = ba\n",
        "\n",
        "\t\treturn bf\n",
        "\n",
        "\tdef add(self, item):\n",
        "\t\t'''\n",
        "\t\tEncode and insert an item into the filter\n",
        "\t\t'''\n",
        "\t\tdigests = []\n",
        "\t\tfor i in range(self.hash_count):\n",
        "\n",
        "\t\t\t# create digest for given item.\n",
        "\t\t\t# using SHA256\n",
        "      # checking the bit value\n",
        "      # set bit value = position mod m\n",
        "\t\t\tdigest = int(hashlib.sha256(item.encode()).hexdigest(),16) % self.size\n",
        "\t\t\tdigests.append(digest)\n",
        "\n",
        "\t\t\t# set the bit True in bit_array\n",
        "\t\t\tself.bit_array[digest] = True\n",
        "\n",
        "\tdef check(self, item):\n",
        "\t\t'''\n",
        "\t\tCheck for existence of an item in filter\n",
        "\t\t'''\n",
        "\t\tfor i in range(self.hash_count):\n",
        "\t\t\tdigest = int(hashlib.sha256(item.encode()).hexdigest(),16) % self.size\n",
        "\t\t\tif self.bit_array[digest] == False:\n",
        "\n",
        "\t\t\t\t# if any of bit is False then,its not present\n",
        "\t\t\t\t# in filter\n",
        "\t\t\t\t# else there is probability that it exist\n",
        "\t\t\t\treturn False\n",
        "\t\treturn True\n",
        "\n",
        "\t@classmethod\n",
        "\tdef get_size(self, n, p):\n",
        "\t\t'''\n",
        "\t\tReturn the size of bit array(m) to used using\n",
        "\t\tfollowing formula\n",
        "\t\tm = -(n * lg(p)) / (lg(2)^2)\n",
        "\t\tn : int\n",
        "\t\t\tnumber of items expected to be stored in filter\n",
        "\t\tp : float\n",
        "\t\t\tFalse Positive probability in decimal\n",
        "\t\t'''\n",
        "\t\tm = -(n * math.log(p))/(math.log(2)**2)\n",
        "\t\treturn int(m)\n",
        "\n",
        "\t@classmethod\n",
        "\tdef get_hash_count(self, m, n):\n",
        "\t\t'''\n",
        "\t\tReturn the hash function(k) to be used using\n",
        "\t\tfollowing formula\n",
        "\t\tk = (m/n) * lg(2)\n",
        "\n",
        "\t\tm : int\n",
        "\t\t\tsize of bit array\n",
        "\t\tn : int\n",
        "\t\t\tnumber of items expected to be stored in filter\n",
        "\t\t'''\n",
        "\t\tk = (m/n) * math.log(2)\n",
        "\t\treturn int(k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkqSg2EP3Fyd"
      },
      "source": [
        "# FUNCTION: create_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kr9xVrlS_3O"
      },
      "outputs": [],
      "source": [
        "def create_list(array_count, element_count, fp_prob):\n",
        "  '''\n",
        "  Function to create multiple array that recall bloom filter method.\n",
        "  '''\n",
        "  array_bf = []\n",
        "  a = array_count\n",
        "  n = element_count\n",
        "  p = fp_prob\n",
        "\n",
        "  for i in range(a):\n",
        "    BF = BloomFilter(n, p)\n",
        "    array_bf.append(BF)\n",
        "\n",
        "  return array_bf\n",
        "\n",
        "  # baca data dari csv, insert."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-mC__KjX5iN"
      },
      "source": [
        "# DCOMB: Layer 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DbpYJKa16Am"
      },
      "source": [
        "## Static"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kwgR71DwNDE"
      },
      "outputs": [],
      "source": [
        "def create_layer_1_static(layer_1_static_list):\n",
        "  layer_1_static_list.append(BloomFilter(n, p))\n",
        "\n",
        "  return layer_1_static_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fJpyJUNwkR8"
      },
      "outputs": [],
      "source": [
        "def add_layer_1_static(layer_1_static_list, block_id, block_indexes_df):\n",
        "  layer_1_static_list\n",
        "\n",
        "  for index in block_indexes_df['index']:\n",
        "    layer_1_static_list[block_id].add(index)\n",
        "\n",
        "  return layer_1_static_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dZAsY35T1kG"
      },
      "outputs": [],
      "source": [
        "def query_layer_1_static(layer_1_static_list, block_id, index):\n",
        "  return layer_1_static_list[block_id].check(index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DIhuGK82IpS"
      },
      "source": [
        "## Dynamic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03KwN1sYzODZ"
      },
      "outputs": [],
      "source": [
        "def create_layer_1_dynamic(layer_1_dynamic_list, block_indexes_df):\n",
        "  layer_1_dynamic_list.append(BloomFilter(len(block_indexes_df.index), p))\n",
        "\n",
        "  return layer_1_dynamic_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNNge5vFzVnX"
      },
      "outputs": [],
      "source": [
        "def add_layer_1_dynamic(layer_1_dynamic_list, block_id, block_indexes_df):\n",
        "  for index in block_indexes_df['index']:\n",
        "    layer_1_dynamic_list[block_id].add(index)\n",
        "\n",
        "  return layer_1_dynamic_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGAYi_SbAxPb"
      },
      "outputs": [],
      "source": [
        "def query_layer_1_dynamic(layer_1_dynamic_list, block_id, index):\n",
        "  return layer_1_dynamic_list[block_id].check(index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCAGczhkcwhJ"
      },
      "source": [
        "# DCOMB: Layer 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQjtR-M-EwfK"
      },
      "outputs": [],
      "source": [
        "def get_pk_from_index(index):\n",
        "  # index consist of\n",
        "  # stream head hash (40)+ cipher hash (40) + pk\n",
        "  return index[80:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mM8KY-8ajint"
      },
      "outputs": [],
      "source": [
        "def pk_to_pk_code(pk):\n",
        "  return ''.join(format(x, 'b') for x in bytearray(pk, 'UTF-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERzMjAZBb4Ue"
      },
      "outputs": [],
      "source": [
        "def get_longest_pk(block_index_df):\n",
        "  longest_pk = ''\n",
        "\n",
        "  for index in block_index_df['index']:\n",
        "    current_index_pk = get_pk_from_index(index)\n",
        "\n",
        "    if len(current_index_pk) > len(longest_pk):\n",
        "      longest_pk = current_index_pk\n",
        "\n",
        "  return longest_pk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wU5PilVteAWW"
      },
      "outputs": [],
      "source": [
        "def get_padded_pk_code_list(block_index_df, block_longest_pk_code):\n",
        "  block_pk_code_length = len(block_longest_pk_code)\n",
        "  block_pk_code_list = []\n",
        "\n",
        "  for index in block_index_df['index']:\n",
        "    # padd 0 (ljust) of each index pk until len(pk_code) == len(block_longest_pk_code)\n",
        "    pk_code = pk_to_pk_code(get_pk_from_index(index))\n",
        "    pk_code = pk_code.ljust(block_pk_code_length, '0')\n",
        "\n",
        "    block_pk_code_list.append(pk_code)\n",
        "\n",
        "  return block_pk_code_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1HfMSp7YfB1"
      },
      "source": [
        "## 2.1. UBF1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDll6rtMH4r5"
      },
      "outputs": [],
      "source": [
        "def create_ubf1(ubf1_list, block_id, block_longest_pk_code):\n",
        "  f = len(block_longest_pk_code)\n",
        "  union_bits_count = f - a + 1\n",
        "\n",
        "  ubf1 = create_list(union_bits_count, n, p)\n",
        "\n",
        "  ubf1_list.append(ubf1)\n",
        "  \n",
        "  return ubf1_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGqsvHhlhbi1"
      },
      "outputs": [],
      "source": [
        "def add_ubf1(ubf1_list, block_id, block_longest_pk_code, block_pk_code_list):\n",
        "  for pk_code in block_pk_code_list:    \n",
        "\n",
        "    for u in range(len(ubf1_list[block_id])):\n",
        "      ubf1_list[block_id][u].add(pk_code[:a])\n",
        "\n",
        "      pk_code = pk_code[1:]\n",
        "    \n",
        "  return ubf1_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN3u2o1pBQQq"
      },
      "outputs": [],
      "source": [
        "def query_ubf1(ubf1_list, block_id, pk_code):\n",
        "  query_result = True\n",
        "\n",
        "  for u in range(len(ubf1_list[block_id])):\n",
        "    query_result = query_result and ubf1_list[block_id][u].check(pk_code[:a])\n",
        "\n",
        "    pk_code = pk_code[1:]\n",
        "\n",
        "  return query_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRaRt87dYhWB"
      },
      "source": [
        "## 2.1. UBF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1CUnMblGTxo"
      },
      "outputs": [],
      "source": [
        "def create_ubf2(ubf2_list, block_id, block_longest_pk_code):\n",
        "  f = len(block_longest_pk_code)\n",
        "  union_bits_count = -(f // -a) # equal to ceil(f / a)\n",
        "\n",
        "  ubf2 = create_list(union_bits_count, n, p)\n",
        "\n",
        "  ubf2_list.append(ubf2)\n",
        "  \n",
        "  return ubf2_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAOTftFuHDSN"
      },
      "outputs": [],
      "source": [
        "def add_ubf2(ubf2_list, block_id, block_longest_pk_code, block_pk_code_list):  \n",
        "  for pk_code in block_pk_code_list:\n",
        "    temp = pk_code \n",
        "\n",
        "    for u in range(len(ubf2_list[block_id])):\n",
        "      ubf2_list[block_id][u].add(pk_code[:a])\n",
        "\n",
        "      pk_code = pk_code[a:]\n",
        "\n",
        "  return ubf2_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frrfMA4jE3-e"
      },
      "outputs": [],
      "source": [
        "def query_ubf2(ubf2_list, block_id, pk_code):\n",
        "  query_result = True\n",
        "\n",
        "  for u in range(len(ubf2_list[block_id])):\n",
        "    query_result = query_result and ubf2_list[block_id][u].check(pk_code[:a])\n",
        "\n",
        "    pk_code = pk_code[a:]\n",
        "\n",
        "  return query_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkTBl8oAmWt2"
      },
      "source": [
        "## 2.2. DBF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0cpEJVOtHuf"
      },
      "outputs": [],
      "source": [
        "def create_dbf(dbf_list, block_id, block_longest_pk_code):\n",
        "  dbf = create_list(len(block_longest_pk_code), n, p)\n",
        "\n",
        "  dbf_list.append(dbf)\n",
        "  \n",
        "  return dbf_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Twc6cMUQtnUv"
      },
      "outputs": [],
      "source": [
        "def add_dbf(dbf_list, block_id, block_longest_pk_code, block_indexes_df):  \n",
        "  for i in range(len(block_longest_pk_code)):\n",
        "    if int(block_longest_pk_code[i]) == 0: continue\n",
        "    \n",
        "    for index in block_indexes_df['index']:\n",
        "      dbf_list[block_id][i].add(index)\n",
        "\n",
        "  return dbf_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpR5H2UckopC"
      },
      "outputs": [],
      "source": [
        "def query_dbf(dbf_list, block_id, longest_pk_code, index):  \n",
        "  query_result = True\n",
        "\n",
        "  for i in range(len(block_longest_pk_code)):\n",
        "    if int(block_longest_pk_code[i]) == 0: continue\n",
        "    \n",
        "    query_result = query_result and dbf_list[block_id][i].check(index)\n",
        "\n",
        "  return query_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK-XadwNV26m"
      },
      "source": [
        "# GLOBAL VARIABLES\n",
        "To store generated dcomb result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gd16hR64VONi"
      },
      "outputs": [],
      "source": [
        "layer_1_static_list = []\n",
        "layer_1_dynamic_list = []\n",
        "layer_2_ubf1_list = []\n",
        "layer_2_ubf2_list = []\n",
        "layer_2_dbf_list = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiR9VZCFjueV"
      },
      "source": [
        "# BENCHMARK: Insert\n",
        "Insert is done per block basis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MEb_CwM7jueW"
      },
      "outputs": [],
      "source": [
        "insert_time_df = pd.DataFrame(data = {\n",
        "    'block_id': [],\n",
        "    'layer_1_static': [],\n",
        "    'layer_1_dynamic': [],\n",
        "    'layer_2_ubf1': [],\n",
        "    'layer_2_ubf2': [],\n",
        "    'layer_2_dbf': [],\n",
        "    'preparation': [], # time used to grab pk code from index, convert it to pk code\n",
        "})\n",
        "\n",
        "# iterate through every block available in prepared data\n",
        "for block_id in block_df['block_id']:\n",
        "  # get all indexes for corresponding block\n",
        "  block_indexes_df = index_df.loc[index_df['block_id'] == block_id]\n",
        "\n",
        "  # preparation\n",
        "  t0_prep = time.perf_counter()\n",
        "\n",
        "  block_longest_pk = get_longest_pk(block_indexes_df)\n",
        "  block_longest_pk_code = pk_to_pk_code(block_longest_pk)\n",
        "\n",
        "  pk_code_list = get_padded_pk_code_list(block_indexes_df, block_longest_pk_code)\n",
        "\n",
        "  t1_prep = time.perf_counter()\n",
        "  tn_prep = t1_prep - t0_prep\n",
        "  # preparation\n",
        "\n",
        "\n",
        "\n",
        "  # insert to layer 1 static\n",
        "  t0_l1s = time.perf_counter()\n",
        "\n",
        "  layer_1_static_list = create_layer_1_static(layer_1_static_list)\n",
        "  layer_1_static_list = add_layer_1_static(layer_1_static_list, block_id, block_indexes_df)\n",
        "\n",
        "  t1_l1s = time.perf_counter()\n",
        "  tn_l1s = t1_l1s - t0_l1s\n",
        "  # endof insert to layer 1 static\n",
        "\n",
        "\n",
        "\n",
        "  # insert to layer 1 dynamic\n",
        "  t0_l1d = time.perf_counter()\n",
        "\n",
        "  layer_1_dynamic_list = create_layer_1_dynamic(layer_1_dynamic_list, block_indexes_df)\n",
        "  layer_1_dynamic_list = add_layer_1_dynamic(layer_1_dynamic_list, block_id, block_indexes_df)\n",
        "\n",
        "  t1_l1d = time.perf_counter()\n",
        "  tn_l1d = t1_l1d - t0_l1d\n",
        "  # endof insert to layer 1 dynamic\n",
        "\n",
        "\n",
        "\n",
        "  # insert to layer 2 ubf1\n",
        "  t0_ubf1 = time.perf_counter()\n",
        "\n",
        "  layer_2_ubf1_list = create_ubf1(layer_2_ubf1_list, block_id, block_longest_pk_code)\n",
        "  layer_2_ubf1_list = add_ubf1(layer_2_ubf1_list, block_id, block_longest_pk_code, pk_code_list)\n",
        "\n",
        "  t1_ubf1 = time.perf_counter()\n",
        "  tn_ubf1 = t1_ubf1 - t0_ubf1\n",
        "  # endof insert to layer 2 ubf1\n",
        "\n",
        "\n",
        "  # insert to layer 2 ubf2\n",
        "  t0_ubf2 = time.perf_counter()\n",
        "\n",
        "  layer_2_ubf2_list = create_ubf2(layer_2_ubf2_list, block_id, block_longest_pk_code)\n",
        "  layer_2_ubf2_list = add_ubf2(layer_2_ubf2_list, block_id, block_longest_pk_code, pk_code_list)\n",
        "\n",
        "  t1_ubf2 = time.perf_counter()\n",
        "  tn_ubf2 = t1_ubf2 - t0_ubf2\n",
        "  # endof insert to layer 2 ubf2\n",
        "\n",
        "\n",
        "  # insert to layer 2 dbf\n",
        "  t0_dbf = time.perf_counter()\n",
        "\n",
        "  layer_2_dbf_list = create_dbf(layer_2_dbf_list, block_id, block_longest_pk_code)\n",
        "  layer_2_dbf_list = add_dbf(layer_2_dbf_list, block_id, block_longest_pk_code, block_indexes_df)\n",
        "\n",
        "  t1_dbf = time.perf_counter()\n",
        "  tn_dbf = t1_dbf - t0_dbf\n",
        "  # endof insert to layer 2 dbf\n",
        "\n",
        "\n",
        "  insert_time_df = insert_time_df.append({\n",
        "      'block_id': block_id,\n",
        "      'layer_1_static': tn_l1s,\n",
        "      'layer_1_dynamic': tn_l1d,\n",
        "      'layer_2_ubf1': tn_ubf1,\n",
        "      'layer_2_ubf2': tn_ubf2,\n",
        "      'layer_2_dbf': tn_dbf,\n",
        "      'preparation': tn_prep,\n",
        "  }, ignore_index=True)\n",
        "\n",
        "insert_time_df['block_id'] = insert_time_df['block_id'].apply(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "11TakqJnjueX",
        "outputId": "481128cc-b69e-49c5-aa00-8244bd371bc8"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_0cc4ed46-3cfe-41a3-884b-08c0745b624b\", \"insert_time_df.csv\", 128742)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     block_id  layer_1_static  ...  layer_2_dbf  preparation\n",
            "0           0        0.000196  ...     0.181354     0.000939\n",
            "1           1        0.000198  ...     0.177693     0.000873\n",
            "2           2        0.000201  ...     0.204356     0.001001\n",
            "3           3        0.000193  ...     0.185383     0.000910\n",
            "4           4        0.000201  ...     0.175817     0.000879\n",
            "..        ...             ...  ...          ...          ...\n",
            "995       995        0.001017  ...     0.994705     0.004000\n",
            "996       996        0.000985  ...     1.010114     0.003947\n",
            "997       997        0.000959  ...     1.001142     0.004365\n",
            "998       998        0.000971  ...     1.013230     0.004289\n",
            "999       999        0.000964  ...     0.999831     0.003978\n",
            "\n",
            "[1000 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "# export to csv\n",
        "insert_time_df.to_csv('insert_time_df.csv', index=False)\n",
        "files.download('insert_time_df.csv')\n",
        "\n",
        "print(insert_time_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anLN6JQEjueX"
      },
      "source": [
        "# BENCHMARK: Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Xn2K07O-jueX"
      },
      "outputs": [],
      "source": [
        "query_time_df = pd.DataFrame(data = {\n",
        "    'block_id': [],\n",
        "    'index': [],\n",
        "    'result_layer_1_static': [],\n",
        "    'time_layer_1_static': [],\n",
        "    'result_layer_1_dynamic': [],\n",
        "    'time_layer_1_dynamic': [],\n",
        "    'result_layer_2_ubf1': [],\n",
        "    'time_layer_2_ubf1': [],\n",
        "    'result_layer_2_ubf2': [],\n",
        "    'time_layer_2_ubf2': [],\n",
        "    'result_layer_2_dbf': [],\n",
        "    'time_layer_2_dbf': [],\n",
        "    'preparation': [],\n",
        "})\n",
        "\n",
        "# iterate through every block available in prepared data\n",
        "for block_id in block_df['block_id']:\n",
        "  block_indexes_df = index_df.loc[index_df['block_id'] == block_id]\n",
        "\n",
        "  block_longest_pk = get_longest_pk(block_indexes_df)\n",
        "  block_longest_pk_code = pk_to_pk_code(block_longest_pk)\n",
        "\n",
        "  for index in block_indexes_df['index']:\n",
        "    # # preparation\n",
        "    t0_prep = time.perf_counter()\n",
        "\n",
        "    pk = get_pk_from_index(index)\n",
        "    pk_code = pk_to_pk_code(pk)\n",
        "    pk_code = pk_code.ljust(len(block_longest_pk_code), '0')\n",
        "\n",
        "    t1_prep = time.perf_counter()\n",
        "    tn_prep = t1_prep - t0_prep\n",
        "    # # preparation\n",
        "\n",
        "\n",
        "    # # query to layer 1 static\n",
        "    t0_l1s = time.perf_counter()\n",
        "\n",
        "    r_l1s = layer_1_static_list[block_id].check(index)\n",
        "\n",
        "    t1_l1s = time.perf_counter()\n",
        "    tn_l1s = t1_l1s - t0_l1s\n",
        "    # # endof query to layer 1 static\n",
        "\n",
        "\n",
        "\n",
        "    # # query to layer 1 dynamic\n",
        "    t0_l1d = time.perf_counter()\n",
        "\n",
        "    r_l1d = layer_1_dynamic_list[block_id].check(index)\n",
        "\n",
        "    t1_l1d = time.perf_counter()\n",
        "    tn_l1d = t1_l1d - t0_l1d\n",
        "    # # endof query to layer 1 dynamic\n",
        "\n",
        "\n",
        "\n",
        "    # # query to layer 2 ubf1\n",
        "    t0_ubf1 = time.perf_counter()\n",
        "\n",
        "    r_ubf1 = query_ubf1(layer_2_ubf1_list, block_id, pk_code)\n",
        "\n",
        "    t1_ubf1 = time.perf_counter()\n",
        "    tn_ubf1 = t1_ubf1 - t0_ubf1\n",
        "    # # endof query to layer 2 ubf1\n",
        "\n",
        "\n",
        "    # # query to layer 2 ubf2\n",
        "    t0_ubf2 = time.perf_counter()\n",
        "\n",
        "    r_ubf2 = query_ubf2(layer_2_ubf2_list, block_id, pk_code)\n",
        "\n",
        "    t1_ubf2 = time.perf_counter()\n",
        "    tn_ubf2 = t1_ubf2 - t0_ubf2\n",
        "    # # endof query to layer 2 ubf2\n",
        "\n",
        "\n",
        "    # # insert to layer 2 dbf\n",
        "    t0_dbf = time.perf_counter()\n",
        "\n",
        "    r_dbf = query_dbf(layer_2_dbf_list, block_id, block_longest_pk_code, index)\n",
        "\n",
        "    t1_dbf = time.perf_counter()\n",
        "    tn_dbf = t1_dbf - t0_dbf\n",
        "    # # endof insert to layer 2 dbf\n",
        "\n",
        "\n",
        "    query_time_df = query_time_df.append({\n",
        "        'block_id': block_id,\n",
        "        'index': index,\n",
        "        'result_layer_1_static': r_l1s,\n",
        "        'time_layer_1_static': tn_l1s,\n",
        "        'result_layer_1_dynamic': r_l1d,\n",
        "        'time_layer_1_dynamic': tn_l1d,\n",
        "        'result_layer_2_ubf1': r_ubf1,\n",
        "        'time_layer_2_ubf1': tn_ubf1,\n",
        "        'result_layer_2_ubf2': r_ubf2,\n",
        "        'time_layer_2_ubf2': tn_ubf2,\n",
        "        'result_layer_2_dbf': r_dbf,\n",
        "        'time_layer_2_dbf': tn_dbf,\n",
        "\n",
        "        'preparation': tn_prep,\n",
        "    }, ignore_index=True)\n",
        "\n",
        "query_time_df['block_id'] = query_time_df['block_id'].apply(int)\n",
        "query_time_df['result_layer_1_static'] = query_time_df['result_layer_1_static'].apply(bool)\n",
        "query_time_df['result_layer_1_dynamic'] = query_time_df['result_layer_1_dynamic'].apply(bool)\n",
        "query_time_df['result_layer_2_ubf1'] = query_time_df['result_layer_2_ubf1'].apply(bool)\n",
        "query_time_df['result_layer_2_ubf2'] = query_time_df['result_layer_2_ubf2'].apply(bool)\n",
        "query_time_df['result_layer_2_dbf'] = query_time_df['result_layer_2_dbf'].apply(bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u6Ko1VEXjueZ",
        "outputId": "594780b9-678e-4cf5-9d76-06bbc31d7ef8"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_1fa0f1ea-1550-4d13-8269-d18ef52f7b63\", \"query_time_df.csv\", 15604243)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       block_id  ... preparation\n",
            "0             0  ...    0.000107\n",
            "1             0  ...    0.000136\n",
            "2             0  ...    0.000130\n",
            "3             0  ...    0.000120\n",
            "4             0  ...    0.000125\n",
            "...         ...  ...         ...\n",
            "27631       999  ...    0.000129\n",
            "27632       999  ...    0.000127\n",
            "27633       999  ...    0.000115\n",
            "27634       999  ...    0.000130\n",
            "27635       999  ...    0.000112\n",
            "\n",
            "[27636 rows x 13 columns]\n"
          ]
        }
      ],
      "source": [
        "# export to csv\n",
        "query_time_df.to_csv('query_time_df.csv', index=False)\n",
        "files.download('query_time_df.csv')\n",
        "\n",
        "print(query_time_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKDIOVjIdUPO"
      },
      "source": [
        "# BENCHMARK: FPP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OV6AT02RdXqn"
      },
      "outputs": [],
      "source": [
        "fpp_df = pd.DataFrame(data = {\n",
        "    'block_id': [],\n",
        "    'layer_1_static': [],\n",
        "    'layer_1_dynamic': [],\n",
        "    'layer_2_ubf1': [],\n",
        "    'layer_2_ubf2': [],\n",
        "    'layer_2_dbf': [],\n",
        "})\n",
        "\n",
        "for block_id in block_df['block_id']:\n",
        "\n",
        "  # calculate fpp for layer 1 static\n",
        "  l1s_n = n # n for layer 1 static\n",
        "  l1s_k = layer_1_static_list[block_id].hash_count # k for layer 1 static\n",
        "\n",
        "  l1s_fpp = pow(1 - (pow(1 - (1 / 383), (l1s_n * l1s_k))), l1s_k)\n",
        "  # endof calculate fpp for layer 1 static\n",
        "\n",
        "\n",
        "\n",
        "  # calculate fpp for layer 1 dynamic\n",
        "  l1d_n = len(index_df.loc[index_df['block_id'] == block_id].index) # n for layer 1 dynamic\n",
        "  l1d_k = layer_1_dynamic_list[block_id].hash_count # k layer 1 dynamic\n",
        "\n",
        "  l1d_fpp = pow(1 - (pow(1 - (1 / 383), (l1d_n * l1d_k))), l1d_k)\n",
        "  # endof calculate fpp for layer 1 dynamic\n",
        "\n",
        "\n",
        "\n",
        "  block_indexes_df = index_df.loc[index_df['block_id'] == block_id]\n",
        "  block_longest_pk = get_longest_pk(block_indexes_df)\n",
        "  block_longest_pk_code = pk_to_pk_code(block_longest_pk)\n",
        "\n",
        "  f = len(block_longest_pk_code) # f for ubf1, ubf2, and dbf\n",
        "\n",
        "\n",
        "\n",
        "  # calculate fpp for layer 2 ubf1\n",
        "\n",
        "  # get constant from ubf_id 0 for the block\n",
        "  # since all bf in same block are having the same properties\n",
        "  ubf1_k = layer_2_ubf1_list[block_id][0].hash_count # k for ubf1\n",
        "  ubf1_m = layer_2_ubf1_list[block_id][0].size # m for ubf1\n",
        "\n",
        "  ubf1_fpp1 = (f - a + 2)\n",
        "  ubf1_fpp2 = pow(1 - pow(math.e, -1 * ((n * ubf1_k) / ubf1_m)), ubf1_k)\n",
        "  ubf1_fpp = ubf1_fpp1 * ubf1_fpp2 \n",
        "  # endof calculate fpp for layer 2 ubf1\n",
        "\n",
        "\n",
        "\n",
        "  # calculate fpp for layer 2 ubf2\n",
        "  \n",
        "  # get constant from ubf_id 0 for the block\n",
        "  # since all bf in same block are having the same properties\n",
        "  ubf2_k = layer_2_ubf2_list[block_id][0].hash_count # k for ubf2\n",
        "  ubf2_m = layer_2_ubf2_list[block_id][0].size # m for ubf2\n",
        "\n",
        "  ubf2_fpp1 = -(f // -a) + 1\n",
        "  ubf2_fpp2 = pow(1 - pow(math.e, -1 * ((n * ubf2_k) / ubf2_m)), ubf2_k)\n",
        "  ubf2_fpp = ubf2_fpp1 * ubf2_fpp2 \n",
        "  # endof calculate fpp for layer 2 ubf2\n",
        "\n",
        "\n",
        "  # calculate fpp for layer 2 dbf\n",
        "  dbf_q = a\n",
        "\n",
        "  dbf_fpp1 = pow(p, dbf_q)\n",
        "  dbf_fpp2 = pow(1 - p, f - dbf_q + 2)\n",
        "  dbf_fpp = dbf_fpp1 * dbf_fpp2 \n",
        "  # endof calculate fpp for layer 2 dbf\n",
        "\n",
        "  fpp_df = fpp_df.append({\n",
        "    'block_id': block_id,\n",
        "    'layer_1_static': l1s_fpp,\n",
        "    'layer_1_dynamic': l1d_fpp,\n",
        "    'layer_2_ubf1': ubf1_fpp,\n",
        "    'layer_2_ubf2': ubf2_fpp,\n",
        "    'layer_2_dbf': dbf_fpp,\n",
        "  }, ignore_index=True)\n",
        "\n",
        "fpp_df['block_id'] = fpp_df['block_id'].apply(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QrkVh-gSiDsk",
        "outputId": "4e25f9d0-2937-4b90-cf7d-159b2e4a869b"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_cea13c07-bf40-4f0c-85bd-613fb4a73965\", \"fpp_df.csv\", 90796)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     block_id  layer_1_static  ...  layer_2_ubf2  layer_2_dbf\n",
            "0           0        0.000148  ...      0.004137          0.0\n",
            "1           1        0.000148  ...      0.004137          0.0\n",
            "2           2        0.000148  ...      0.004137          0.0\n",
            "3           3        0.000148  ...      0.004137          0.0\n",
            "4           4        0.000148  ...      0.004137          0.0\n",
            "..        ...             ...  ...           ...          ...\n",
            "995       995        0.000148  ...      0.004137          0.0\n",
            "996       996        0.000148  ...      0.004137          0.0\n",
            "997       997        0.000148  ...      0.004137          0.0\n",
            "998       998        0.000148  ...      0.004137          0.0\n",
            "999       999        0.000148  ...      0.004137          0.0\n",
            "\n",
            "[1000 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "# export to csv\n",
        "fpp_df.to_csv('fpp_df.csv', index=False)\n",
        "files.download('fpp_df.csv')\n",
        "\n",
        "print(fpp_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHhgrOGTjDTz"
      },
      "source": [
        "# BENCHMARK: Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lqo3YLe8_ry0",
        "outputId": "68620248-8c02-4a78-8df3-dde8690e6229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer 1 static: 287000 bits\n"
          ]
        }
      ],
      "source": [
        "layer_1_static_size = 0\n",
        "for block_bf in layer_1_static_list:\n",
        "  layer_1_static_size += block_bf.size\n",
        "\n",
        "print('layer 1 static:', layer_1_static_size, 'bits')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fYvZaAtXATEJ",
        "outputId": "69ffb1f7-f439-4b48-e899-1c895b01630c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer 1 dynamic: 396747 bits\n"
          ]
        }
      ],
      "source": [
        "layer_1_dynamic_size = 0\n",
        "for block_bf in layer_1_dynamic_list:\n",
        "  layer_1_dynamic_size += block_bf.size\n",
        "\n",
        "print('layer 1 dynamic:', layer_1_dynamic_size, 'bits')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RFDyOaVIAg2C",
        "outputId": "20eff185-8d9c-4508-f88f-b103fbfd00ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer 2 ubf1: 299260927 bits\n"
          ]
        }
      ],
      "source": [
        "layer_2_ubf1_size = 0\n",
        "for block in layer_2_ubf1_list:\n",
        "  for bf in block:\n",
        "    layer_2_ubf1_size += bf.size\n",
        "\n",
        "print('layer 2 ubf1:', layer_2_ubf1_size, 'bits')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fDwnV3k6A5E7",
        "outputId": "cd868f6d-3ff4-4774-af5c-bea3a1564c04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer 2 ubf2: 861000 bits\n"
          ]
        }
      ],
      "source": [
        "layer_2_ubf2_size = 0\n",
        "for block in layer_2_ubf2_list:\n",
        "  for bf in block:\n",
        "    layer_2_ubf2_size += bf.size\n",
        "\n",
        "print('layer 2 ubf2:', layer_2_ubf2_size, 'bits')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "whgjlXfcA8qY",
        "outputId": "72ed21bd-bf49-484f-89c9-1c9d37222214"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer 2 dbf: 585973927 bits\n"
          ]
        }
      ],
      "source": [
        "layer_2_dbf_size = 0\n",
        "for block in layer_2_dbf_list:\n",
        "  for bf in block:\n",
        "    layer_2_dbf_size += bf.size\n",
        "\n",
        "print('layer 2 dbf:', layer_2_dbf_size, 'bits')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3uiofan_bck"
      },
      "source": [
        "# EXPORT: CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "teEYPlcpk3ad"
      },
      "outputs": [],
      "source": [
        "layer_1_static_df = pd.DataFrame(data = {\n",
        "    'block_id': [],\n",
        "    'bit_array': [],\n",
        "})\n",
        "\n",
        "\n",
        "for i in range(len(layer_1_static_list)):\n",
        "  bit_array = ''.join(str(x) for x in layer_1_static_list[i].bit_array)\n",
        "  layer_1_static_df = layer_1_static_df.append({\n",
        "      'block_id': i,\n",
        "      'bit_array': bit_array\n",
        "  }, ignore_index=True)\n",
        "\n",
        "\n",
        "layer_1_static_df['block_id'] = layer_1_static_df['block_id'].apply(int)\n",
        "\n",
        "# print(layer_1_static_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z4Gne2bcpbkS",
        "outputId": "d219d681-9f28-4494-af42-ac1ee800792b"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_08701c7e-e47f-4004-9b04-28436b13809f\", \"layer_1_static_df.csv\", 291909)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "layer_1_static_df.to_csv('layer_1_static_df.csv', index=False)\n",
        "files.download('layer_1_static_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5VWUhrf2lRdw"
      },
      "outputs": [],
      "source": [
        "layer_1_dynamic_df = pd.DataFrame(data = {\n",
        "    'block_id': [],\n",
        "    'bit_array': [],\n",
        "})\n",
        "\n",
        "for i in range(len(layer_1_dynamic_list)):\n",
        "  bit_array = ''.join(str(x) for x in layer_1_dynamic_list[i].bit_array)\n",
        "  layer_1_dynamic_df = layer_1_dynamic_df.append({\n",
        "      'block_id': i,\n",
        "      'bit_array': bit_array\n",
        "  }, ignore_index=True)\n",
        "\n",
        "\n",
        "layer_1_dynamic_df['block_id'] = layer_1_dynamic_df['block_id'].apply(int)\n",
        "\n",
        "# print(layer_1_dynamic_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Wns2_jr_peH4",
        "outputId": "609572c0-3def-4529-a708-d336ed282ea4"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_859cd98d-9754-4827-9407-dde06c9c6d9a\", \"layer_1_dynamic_df.csv\", 401656)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "layer_1_dynamic_df.to_csv('layer_1_dynamic_df.csv', index=False)\n",
        "files.download('layer_1_dynamic_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUzGUdBOkvhj"
      },
      "outputs": [],
      "source": [
        "layer_2_ubf1_df = pd.DataFrame(data = {\n",
        "    'block_id': [],\n",
        "    'ubf_id': [],\n",
        "    'bit_array': [],\n",
        "})\n",
        "\n",
        "for i in range(len(layer_2_ubf1_list)):\n",
        "  for j in range(len(layer_2_ubf1_list[i])):\n",
        "    bit_array = ''.join(str(x) for x in layer_2_ubf1_list[i][j].bit_array)\n",
        "\n",
        "    layer_2_ubf1_df = layer_2_ubf1_df.append({\n",
        "        'block_id': i,\n",
        "        'ubf_id': j,\n",
        "        'bit_array': bit_array\n",
        "    }, ignore_index=True)\n",
        "  \n",
        "  \n",
        "layer_2_ubf1_df['block_id'] = layer_2_ubf1_df['block_id'].apply(int)\n",
        "layer_2_ubf1_df['ubf_id'] = layer_2_ubf1_df['ubf_id'].apply(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvlS2YoYpg6x"
      },
      "outputs": [],
      "source": [
        "layer_2_ubf1_df.to_csv('layer_2_ubf1_df.csv', index=False)\n",
        "files.download('layer_2_ubf1_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgIEEPhujHJg"
      },
      "outputs": [],
      "source": [
        "layer_2_ubf2_df = pd.DataFrame(data = {\n",
        "    'block_id': [],\n",
        "    'ubf_id': [],\n",
        "    'bit_array': [],\n",
        "})\n",
        "\n",
        "for i in range(len(layer_2_ubf2_list)):\n",
        "  for j in range(len(layer_2_ubf2_list[i])):\n",
        "    bit_array = ''.join(str(x) for x in layer_2_ubf2_list[i][j].bit_array)\n",
        "\n",
        "    layer_2_ubf2_df = layer_2_ubf2_df.append({\n",
        "        'block_id': i,\n",
        "        'ubf_id': j,\n",
        "        'bit_array': bit_array\n",
        "    }, ignore_index=True)\n",
        "  \n",
        "  \n",
        "layer_2_ubf2_df['block_id'] = layer_2_ubf2_df['block_id'].apply(int)\n",
        "layer_2_ubf2_df['ubf_id'] = layer_2_ubf2_df['ubf_id'].apply(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZrEoLKkltzS"
      },
      "outputs": [],
      "source": [
        "layer_2_ubf2_df.to_csv('layer_2_ubf2_df.csv', index=False)\n",
        "files.download('layer_2_ubf2_df.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6UT0qJIoKtW"
      },
      "source": [
        "**IMPORTANT NOTE!**\n",
        "\n",
        "**Exporting dbf to csv might cause runtime to crash (out of memory)**\n",
        "\n",
        "**Since block having ~1000 bloom filters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc5Gx63ylZgt"
      },
      "outputs": [],
      "source": [
        "layer_2_dbf_df = pd.DataFrame(data = {\n",
        "    'block_id': [],\n",
        "    'dbf_id': [],\n",
        "    'bit_array': [],\n",
        "})\n",
        "\n",
        "for i in range(len(layer_2_dbf_list)):\n",
        "  for j in range(len(layer_2_dbf_list[i])):\n",
        "    bit_array = ''.join(str(x) for x in layer_2_dbf_list[i][j].bit_array)\n",
        "\n",
        "    layer_2_dbf_df = layer_2_dbf_df.append({\n",
        "        'block_id': i,\n",
        "        'dbf_id': j,\n",
        "        'bit_array': bit_array\n",
        "    }, ignore_index=True)\n",
        "\n",
        "layer_2_dbf_df['block_id'] = layer_2_dbf_df['block_id'].apply(int)\n",
        "layer_2_dbf_df['dbf_id'] = layer_2_dbf_df['dbf_id'].apply(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fypQjiiMoKaF"
      },
      "outputs": [],
      "source": [
        "layer_2_dbf_df.to_csv('layer_2_dbf_df.csv', index=False)\n",
        "files.download('layer_2_dbf_df.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "rkqSg2EP3Fyd"
      ],
      "name": "DCOMB",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}